{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import whisper\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    " \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    " \n",
    "model = whisper.load_model(\"base\", device=device)\n",
    "\n",
    "def download_audio(youtube_url, output_path=\"audio.mp3\"):\n",
    "    \"\"\"Download the audio from a YouTube video.\"\"\"\n",
    "    try:\n",
    "        command = [\n",
    "            \"yt-dlp\",\n",
    "            \"--format\", \"bestaudio\",\n",
    "            \"--extract-audio\",\n",
    "            \"--audio-format\", \"mp3\",\n",
    "            \"--output\", output_path,\n",
    "            youtube_url,\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Audio downloaded to {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribe the audio using Whisper.\"\"\"\n",
    "    try:\n",
    "        print(\"Extracting transcript\")\n",
    "        result = model.transcribe(audio_path)\n",
    "        return result  # Contains text and timestamps\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_transcript_with_timestamps(transcript, output_file=\"transcript.txt\"):\n",
    "    \"\"\"Save the transcript with timestamps to a file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file, \"w\") as file:\n",
    "            for segment in transcript['segments']:\n",
    "                start_time = segment['start']\n",
    "                end_time = segment['end']\n",
    "                text = segment['text']\n",
    "                file.write(f\"[{start_time:.2f} - {end_time:.2f}] {text}\\n\")\n",
    "        print(f\"Transcript saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transcript: {e}\")\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def detect_terms_to_exclude(text:str):\n",
    "    \"\"\"Detect terms that are likely to be technical or domain-specific.\"\"\"\n",
    "  \n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "    patterns = [\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"machine\"},\n",
    "                {\"lower\": \"learning\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"artificial\"},\n",
    "                {\"lower\": \"intelligence\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"data\"},\n",
    "                {\"lower\": \"science\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"ML\"},\n",
    "            ]\n",
    "        },\n",
    "          {\n",
    "            \"label\": \"PERSON\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"Rover\"},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": \"(?i)^ai$\"}}]\n",
    "        },\n",
    "        {\n",
    "                \"label\": \"LINK\",\n",
    "                \"pattern\": [\n",
    "                    {\"TEXT\": {\"REGEX\": r\"https?://[^\\s]+\"}}\n",
    "                ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\") \n",
    "    ruler.add_patterns(patterns)\n",
    "\n",
    "    doc = nlp(text)     \n",
    " \n",
    "    exclude_terms = []\n",
    " \n",
    "    for ent in doc.ents:\n",
    "        exclude_terms.append(ent.text)\n",
    "    \n",
    " \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\" or (token.is_upper and len(token) > 1):  \n",
    "            exclude_terms.append(token.text)\n",
    "\n",
    "    exclude_terms = [term for term in exclude_terms if not re.search(r\"(\\n|%|\\d{1,2}%|^\\d{1,2}$)\", term)]\n",
    "    exclude_terms = list(set(exclude_terms))\n",
    "    \n",
    "    return exclude_terms\n",
    "\n",
    " \n",
    " \n",
    "def generate_translation_prompt(english_text, exclude_terms, custom_terms):\n",
    " \n",
    "    exclusion_list = \"\\n\".join([f\"- {term}\" for term in exclude_terms])\n",
    " \n",
    "    custom_translations = \"\\n\".join([f\"- \\\"{key}\\\" should be translated as \\\"{value}\\\"\" for key, value in custom_terms.items()])\n",
    "    \n",
    "  \n",
    "    instructions = f\"\"\"\n",
    "    Translate the following English text to Burmese (Myanmar) while ensuring the following:\n",
    "    \n",
    "    1. **Exclude specific terms from translation**:\n",
    "        {exclusion_list}\n",
    "        These terms should remain in English and not be translated.\n",
    "    \n",
    "    2. **For specific phrases, use custom translations**:\n",
    "        {custom_translations}\n",
    "        These phrases should be translated exactly as indicated.\n",
    "\n",
    "    The translation should respect the context and accurately convey the meaning of the original text while maintaining these exclusions and custom translations.\n",
    "    \"\"\"\n",
    " \n",
    "    prompt = f\"{instructions}\\n\\nHere is the English text you need to translate:\\n\\n{english_text}\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def save_file(filepath: str, content: str):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "        \n",
    "def read_file(filepath:str):\n",
    "    with open(filepath , \"r\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "\n",
    "def translate_english_to_myanmar_with_transformer(text, exclude_terms=None, custom_terms=None):\n",
    "    if exclude_terms is None:\n",
    "        exclude_terms = []\n",
    "    if custom_terms is None:\n",
    "        custom_terms = {}\n",
    " \n",
    "    placeholders = {}\n",
    "    for idx, (eng_term, myanmar_term) in enumerate(custom_terms.items()):\n",
    "        placeholder = f\"__CUSTOM_TERM_{idx}__\"\n",
    "        text = text.replace(eng_term, placeholder)\n",
    "        placeholders[placeholder] = myanmar_term\n",
    "\n",
    "    \n",
    "    for idx, term in enumerate(exclude_terms):\n",
    "        placeholder = f\"__TERM_{idx}__\"\n",
    "        text = text.replace(term, placeholder)\n",
    "        placeholders[placeholder] = term\n",
    "    print(f\"optimzed text: {text}\")\n",
    "    model_name = \"facebook/m2m100_418M\"\n",
    "    tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "    model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "    tokenizer.src_lang = \"en\"\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    \n",
    "    generated_tokens = model.generate(**encoded_text, forced_bos_token_id=tokenizer.get_lang_id(\"my\"))\n",
    "    translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "     \n",
    "    for placeholder, term in placeholders.items():\n",
    "        translated_text = translated_text.replace(placeholder, term)\n",
    "\n",
    "    return translated_text\n",
    " \n",
    "\n",
    "\n",
    "def translate_with_cohere(text, exclude_terms=None, custom_terms=None):\n",
    "    import cohere\n",
    "    api_key=\"\"\n",
    "    co = cohere.Client(api_key=api_key)\n",
    "    if exclude_terms is None:\n",
    "        exclude_terms = []\n",
    "    if custom_terms is None:\n",
    "        custom_terms = {}\n",
    " \n",
    "    exclusion_text = \"\\n\".join([f\"- {term}\" for term in exclude_terms])\n",
    "    custom_terms_text = \"\\n\".join([f\"'{eng_term}' => '{myanmar_term}'\" for eng_term, myanmar_term in custom_terms.items()])\n",
    "\n",
    " \n",
    "    prompt = f\"\"\"\n",
    "    Translate the following English text to Burmese (Myanmar) while keeping the original English terms for special terms.\n",
    "    Please exclude the following terms from translation: \n",
    "    {exclusion_text}\n",
    "    Also, translate the following custom terms as specified:\n",
    "    {custom_terms_text}\n",
    "\n",
    "    English text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    response = co.generate(\n",
    "        model=\"command-r-08-2024\", \n",
    "        prompt=prompt,\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "   \n",
    "    translated_text = response.generations[0].text\n",
    "\n",
    "    return translated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=DmgGGUYn2c8\"\n",
    "output_filename = \"trnascript.txt\"\n",
    "audio_file = download_audio(youtube_url)\n",
    "\n",
    "if audio_file:\n",
    "\n",
    "    transcript = transcribe_audio(audio_file)\n",
    "    \n",
    "    if transcript:\n",
    "\n",
    "        save_transcript_with_timestamps(transcript, output_filename)\n",
    "\n",
    "    os.remove(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms to Exclude: ['Skill', 'Skills', 'Menu', 'Liberation', 'Bar', 'Forte Circuit', 'Ultimates', 'Abilities', 'Stagger', 'Ultimate', 'one', 'Quick', 'Swapping', 'Plunge', 'Outro Skills', 'Bars', 'Concerto Energy', 'the Forte Circuit', 'an Outro Skill', 'Perfect', 'Ult', 'One', 'Ultimates / Liberation', 'Gadget', 'Havoc', 'Stamina', 'Energy', 'Dodge', 'Outro', 'Grapple', 'DPS', 'Concerto', 'Damage', 'Concerto Energy / Outro /', 'Intro', 'Echoes', 'Forte', 'Echo', 'Circuit', 'Abilities', 'character', 'icon', 'players', 'player', 'play', 'damage', 'normal attack', 'action', 'actions']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "transcript_filepath = \"transcripts/transcript.txt\"\n",
    "\n",
    "english_text = read_file(transcript_filepath)\n",
    "\n",
    "\n",
    "my_exclude_terms = [\"Abilities\", \"character\", \"icon\", \"players\", \"player\", \"play\", \"damage\", \"normal attack\", \"action\", \"actions\"]\n",
    "\n",
    "exclude_terms = detect_terms_to_exclude(english_text)\n",
    "exclude_terms = exclude_terms + my_exclude_terms\n",
    "\n",
    "\n",
    "print(\"Terms to Exclude:\", exclude_terms)\n",
    "# old\n",
    "#Terms to Exclude: ['Quick', 'Concerto', 'Swap', 'DPS', 'Menu', 'Dodge & Counters', 'Ultimates / Liberation', 'Ultimate', 'Havoc', 'Circuit', 'Perfect', 'Echo', 'Parries', 'Echoes', 'itâ€', 'Energy', 'Utilities', 'Normal, Heavy, and Plunge Attacks', 'Counters', 'One', 'the Utilities Menu', 'Every Forte Circuit', 'Counter', 'Intro', 'Attacks', 'Dodge', 'Normal', 'Ultimates', 'Stagger', 'Gadget', 'Sprinting', 'one', 'charactersâ€', 'though', 'Skill', 'Skills', 'their Intro Skill', 'Damage', 'Heavy', 'the Forte Circuit', 'The Forte Circuit', 'Concerto Energy / Outro', 'Liberation', 'Bars', 'Thoughts', 'Gadgets', 'master', 'Grapple', 'Outro', 'Forte Circuit', 'Plunge', 'Stamina', 'Closing', 'Concerto Energy', 'Ult', 'Intro Skill', 'Forte', 'Bar', 'the Concerto Energy bar', 'Abilities', 'character', 'icon', 'players', 'player', 'play', 'damage', 'normal attack', 'action', 'actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick Concerto Swap DPS Menu Dodge & Counters Ultimates / Liberation Ultimate Havoc Circuit Perfect Echo Parries Echoes itâ€ Energy Utilities Normal, Heavy, and Plunge Attacks Counters One the Utilities Menu Every Forte Circuit Counter Intro Attacks Dodge Normal Ultimates Stagger Gadget Sprinting one charactersâ€ though Skill Skills their Intro Skill Damage Heavy the Forte Circuit The Forte Circuit Concerto Energy / Outro Liberation Bars Thoughts Gadgets master Grapple Outro Forte Circuit Plunge Stamina Closing Concerto Energy Ult Intro Skill Forte Bar the Concerto Energy bar Abilities character icon players player play damage normal attack action actions\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(exclude_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_terms = {\n",
    "        \"for each character\": \"character တစ်ကောင်ချင်းစီအတွက်\",\n",
    "    }\n",
    "\n",
    "transcript_filepath = \"transcripts/transcript.txt\"\n",
    "\n",
    "original_timestamp_text = read_file(transcript_filepath)\n",
    "myanmar_text = generate_translation_prompt(original_timestamp_text, exclude_terms=exclude_terms, custom_terms=custom_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "save_file(\"prompt.txt\", myanmar_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\[\\d+\\.\\d{2} - \\d+\\.\\d{2}\\]\"\n",
    " \n",
    " \n",
    "text = read_file(\"transcripts/transcript.txt\") \n",
    "timestamps = re.findall(pattern, text)\n",
    "\n",
    "time_stamps =\"\" \n",
    "time_stamps += \"\\n\".join(timestamps)\n",
    "\n",
    "save_file(\"timestamps.txt\", time_stamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript (Myanmar): ကဲ ဒါဆိုရင်တော့,\n",
      "segment (English): character\n",
      "transcript (Myanmar): ရဲ့\n",
      "segment (English): Abilities\n",
      "transcript (Myanmar): တွေကို စတင်ကြည့်ရှုရအောင်\n",
      "segment (English): Ult\n",
      "segment (English): Echo\n",
      "segment (English): Skill\n",
      "segment (English): Gadget\n",
      "segment (English): Forte\n",
      "segment (English): Circuit\n",
      "transcript (Myanmar): , နဲ့\n",
      "segment (English): Concerto\n",
      "segment (English): Energy\n",
      "transcript (Myanmar): .\n",
      "ဒါတွေက\n",
      "segment (English): character\n",
      "transcript (Myanmar): တစ်ကောင်ချင်းစီအတွက်\n",
      "အဓိက\n",
      "segment (English): Abilities\n",
      "transcript (Myanmar): တွေဖြစ်ပါတယ်။\n",
      "ပုံကဝိုင်း\n",
      "segment (English): icon\n",
      "transcript (Myanmar): လေးဟာ\n",
      "segment (English): lock\n",
      "segment (English): on\n",
      "segment (English): feature\n",
      "transcript (Myanmar): ဖြစ်ပါတယ်။\n",
      "Audio saved as samples/combined_audio_3538434f-5cf9-4cdf-ae9f-bdecb647cf74.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import uuid\n",
    "from transformers import pipeline\n",
    "import soundfile as sf\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "myanmar_model_name = \"facebook/mms-tts-mya\"\n",
    "english_model_name = \"facebook/mms-tts-eng\"\n",
    "myanmar_model = pipeline(\"text-to-speech\", model=myanmar_model_name)\n",
    "english_model = pipeline(\"text-to-speech\", model=english_model_name)\n",
    "\n",
    "sample_rate = 16000\n",
    "pause_duration = 0.5  \n",
    "\n",
    "myanmar_text = \"\"\"\n",
    "ကဲ ဒါဆိုရင်တော့, character ရဲ့ Abilities တွေကို စတင်ကြည့်ရှုရအောင်\n",
    "Ult, Echo, Skill, Gadget, Forte Circuit, နဲ့ Concerto Energy.\n",
    "ဒါတွေက character တစ်ကောင်ချင်းစီအတွက်\n",
    "အဓိက Abilities တွေဖြစ်ပါတယ်။\n",
    "ပုံကဝိုင်း icon လေးဟာ  lock-on feature ဖြစ်ပါတယ်။\n",
    "\"\"\"\n",
    "\n",
    "def generate_audio(text, model):\n",
    "    speech = model(text)\n",
    "    audio_data = speech[\"audio\"]\n",
    "    if audio_data.ndim == 2 and audio_data.shape[0] == 1:\n",
    "        audio_data = audio_data.squeeze(0)\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "# Extract English words and Myanmar text segments\n",
    "segments = re.split(r'(\\b[A-Za-z]+\\b)', myanmar_text)\n",
    "audio_segments = []\n",
    "\n",
    "for segment in segments:\n",
    "    segment = segment.strip()\n",
    "    if not segment:\n",
    "        continue\n",
    "    if re.match(r'^[A-Za-z]+$', segment):\n",
    "     \n",
    "        print(f\"segment (English): {segment}\")\n",
    "        audio_segments.append(generate_audio(segment, english_model))\n",
    "    else:\n",
    "        if segment.strip() in [\",\", \".\", \"။\", \"၊\", \":\", \";\",\"-\"]:\n",
    "            continue\n",
    "      \n",
    "        print(f\"transcript (Myanmar): {segment}\")\n",
    "        audio_segments.append(generate_audio(segment, myanmar_model))\n",
    "    \n",
    "    # Add pause for newline characters\n",
    "    if '\\n' in segment:\n",
    "        pause = np.zeros(int(pause_duration * sample_rate)) \n",
    "        audio_segments.append(pause)\n",
    "\n",
    "# Combine all audio segments\n",
    "combined_audio = np.concatenate(audio_segments)\n",
    " \n",
    "random_uuid = uuid.uuid4()\n",
    "output_file = f\"samples/combined_audio_{random_uuid}.wav\"\n",
    "sf.write(output_file, combined_audio, sample_rate)\n",
    "print(f\"Audio saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch: Local file found, copying 'C:\\Users\\heinm\\.cache\\huggingface\\hub\\models--speechbrain--tts-tacotron2-ljspeech\\snapshots\\d01e530d6d8e1b388c04b882305867addbed4389\\hyperparams.yaml' -> 'c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\tmpdir_tts\\hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n",
      "INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b78b402a4f473ebdfaaaacabbd8c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.ckpt:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\heinm\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--tts-tacotron2-ljspeech\\\\snapshots\\\\d01e530d6d8e1b388c04b882305867addbed4389\\\\model.ckpt' -> 'c:\\\\Users\\\\heinm\\\\OneDrive\\\\Desktop\\\\mm-tts\\\\tmpdir_tts\\\\model.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfetching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalStrategy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize TTS (tacotron2) and Vocoder (HiFIGAN) with copy strategy\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m tacotron2 \u001b[38;5;241m=\u001b[39m \u001b[43mTacotron2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hparams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeechbrain/tts-tacotron2-ljspeech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmpdir_tts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLocalStrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOPY\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m hifi_gan \u001b[38;5;241m=\u001b[39m HIFIGAN\u001b[38;5;241m.\u001b[39mfrom_hparams(\n\u001b[0;32m     12\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain/tts-hifigan-ljspeech\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     13\u001b[0m     savedir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmpdir_vocoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     14\u001b[0m     local_strategy\u001b[38;5;241m=\u001b[39mLocalStrategy\u001b[38;5;241m.\u001b[39mCOPY\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Running the TTS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py:520\u001b[0m, in \u001b[0;36mPretrained.from_hparams\u001b[1;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, huggingface_cache_dir, overrides_must_match, local_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m pretrainer\u001b[38;5;241m.\u001b[39mset_collect_in(savedir)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# For distributed setups, have this here:\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m \u001b[43mrun_on_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_source\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_auth_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Load on the CPU. Later the params can be moved elsewhere by specifying\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m download_only:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# run_opts={\"device\": ...}\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:105\u001b[0m, in \u001b[0;36mrun_on_main\u001b[1;34m(func, args, kwargs, post_func, post_args, post_kwargs, run_post_on_main)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     post_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 105\u001b[0m \u001b[43mmain_process_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m ddp_barrier()\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:168\u001b[0m, in \u001b[0;36mmain_process_only.<locals>.main_proc_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m MainProcessContext():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m if_main_process():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:289\u001b[0m, in \u001b[0;36mPretrainer.collect_files\u001b[1;34m(self, default_source, use_auth_token, local_strategy)\u001b[0m\n\u001b[0;32m    280\u001b[0m     path \u001b[38;5;241m=\u001b[39m fetch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# run fetch() on the main process, potentially performing downloading\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# which we do NOT want to happen concurrently.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# path needs to be available only if it is a local source w/o symlink\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43mrun_on_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_fetch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_fetch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m loadable_paths[name] \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, FetchSource):\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:105\u001b[0m, in \u001b[0;36mrun_on_main\u001b[1;34m(func, args, kwargs, post_func, post_args, post_kwargs, run_post_on_main)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     post_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 105\u001b[0m \u001b[43mmain_process_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m ddp_barrier()\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:168\u001b[0m, in \u001b[0;36mmain_process_only.<locals>.main_proc_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m MainProcessContext():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m if_main_process():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:280\u001b[0m, in \u001b[0;36mPretrainer.collect_files.<locals>.run_fetch\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Very basic local wrapper to fetch to store the path in a\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mlocal of collect_files\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m**kwargs : dict\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m    Arguments to forward to fetch\"\"\"\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m path\n\u001b[1;32m--> 280\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:398\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, allow_updates, allow_network, save_filename, use_auth_token, revision, huggingface_cache_dir, local_strategy)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found on HF hub\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlink_with_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetched_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:162\u001b[0m, in \u001b[0;36mlink_with_strategy\u001b[1;34m(src, dst, local_strategy)\u001b[0m\n\u001b[0;32m    157\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetch: Local file found, creating symlink \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, src, dst\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     dst\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# remove link or delete file\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_strategy \u001b[38;5;129;01min\u001b[39;00m (LocalStrategy\u001b[38;5;241m.\u001b[39mCOPY, LocalStrategy\u001b[38;5;241m.\u001b[39mCOPY_SKIP_CACHE):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.8-windows-x86_64-none\\Lib\\pathlib.py:1386\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymlink\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.symlink() not available on this system\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1386\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\heinm\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--tts-tacotron2-ljspeech\\\\snapshots\\\\d01e530d6d8e1b388c04b882305867addbed4389\\\\model.ckpt' -> 'c:\\\\Users\\\\heinm\\\\OneDrive\\\\Desktop\\\\mm-tts\\\\tmpdir_tts\\\\model.ckpt'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
