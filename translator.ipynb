{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import whisper\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    " \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    " \n",
    "model = whisper.load_model(\"base\", device=device)\n",
    "\n",
    "def download_audio(youtube_url, output_path=\"audio.mp3\"):\n",
    "    \"\"\"Download the audio from a YouTube video.\"\"\"\n",
    "    try:\n",
    "        command = [\n",
    "            \"yt-dlp\",\n",
    "            \"--format\", \"bestaudio\",\n",
    "            \"--extract-audio\",\n",
    "            \"--audio-format\", \"mp3\",\n",
    "            \"--output\", output_path,\n",
    "            youtube_url,\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Audio downloaded to {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribe the audio using Whisper.\"\"\"\n",
    "    try:\n",
    "        print(\"Extracting transcript\")\n",
    "        result = model.transcribe(audio_path)\n",
    "        return result  # Contains text and timestamps\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_transcript_with_timestamps(transcript, output_file=\"transcript.txt\"):\n",
    "    \"\"\"Save the transcript with timestamps to a file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file, \"w\") as file:\n",
    "            for segment in transcript['segments']:\n",
    "                start_time = segment['start']\n",
    "                end_time = segment['end']\n",
    "                text = segment['text']\n",
    "                file.write(f\"[{start_time:.2f} - {end_time:.2f}] {text}\\n\")\n",
    "        print(f\"Transcript saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transcript: {e}\")\n",
    "\n",
    "def detect_terms_to_exclude(text:str):\n",
    "    \"\"\"Detect terms that are likely to be technical or domain-specific.\"\"\"\n",
    "  \n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "    patterns = [\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"machine\"},\n",
    "                {\"lower\": \"learning\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"artificial\"},\n",
    "                {\"lower\": \"intelligence\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"data\"},\n",
    "                {\"lower\": \"science\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"ML\"},\n",
    "            ]\n",
    "        },\n",
    "          {\n",
    "            \"label\": \"PERSON\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"Rover\"},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": \"(?i)^ai$\"}}]\n",
    "        },\n",
    "        {\n",
    "                \"label\": \"LINK\",\n",
    "                \"pattern\": [\n",
    "                    {\"TEXT\": {\"REGEX\": r\"https?://[^\\s]+\"}}\n",
    "                ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\") \n",
    "    ruler.add_patterns(patterns)\n",
    "\n",
    "    doc = nlp(text)     \n",
    " \n",
    "    exclude_terms = []\n",
    " \n",
    "    for ent in doc.ents:\n",
    "        exclude_terms.append(ent.text)\n",
    "    \n",
    " \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\" or (token.is_upper and len(token) > 1):  \n",
    "            exclude_terms.append(token.text)\n",
    "\n",
    "    exclude_terms = [term for term in exclude_terms if not re.search(r\"(\\n|%|\\d{1,2}%|^\\d{1,2}$)\", term)]\n",
    "    exclude_terms = list(set(exclude_terms))\n",
    "    \n",
    "    return exclude_terms\n",
    "\n",
    " \n",
    " \n",
    "def generate_system_prompt(exclude_terms:list|None=None, custom_terms:dict|None=None):\n",
    " \n",
    "    if exclude_terms is None:\n",
    "        exclude_terms = []\n",
    "    if custom_terms is None:\n",
    "        custom_terms = {}\n",
    " \n",
    "    exclusion_text = \"\\n\".join([f\"- {term}\" for term in exclude_terms])\n",
    "    custom_terms_text = \"\\n\".join([f\"'{eng_term}' => '{myanmar_term}'\" for eng_term, myanmar_term in custom_terms.items()])\n",
    "\n",
    " \n",
    "    prompt = f\"\"\"\n",
    "    Translate the following English text to Burmese (Myanmar) while keeping the original English terms for special terms.\n",
    "    Please exclude the following terms from translation: \n",
    "    {exclusion_text}\n",
    "    Also, translate the following custom terms as specified:\n",
    "    {custom_terms_text}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def save_file(filepath: str, content: str):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "        \n",
    "def read_file(filepath:str):\n",
    "    with open(filepath , \"r\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=DmgGGUYn2c8\"\n",
    "output_filename = \"trnascript.txt\"\n",
    "audio_file = download_audio(youtube_url)\n",
    "\n",
    "if audio_file:\n",
    "\n",
    "    transcript = transcribe_audio(audio_file)\n",
    "    \n",
    "    if transcript:\n",
    "\n",
    "        save_transcript_with_timestamps(transcript, output_filename)\n",
    "\n",
    "    os.remove(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms to Exclude: ['Energy', 'damage', 'players', 'Abilities', 'an Outro Skill', 'actions', 'Concerto Energy', 'Ult', 'Concerto Energy / Outro /', 'Forte Circuit', 'icon', 'Concerto', 'action', 'Circuit', 'play', 'normal attack', 'Skill', 'player', 'Gadget', 'Forte', 'Intro', 'Outro', 'Echo', 'character']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "transcript_filepath = \"transcripts/transcript.txt\"\n",
    "\n",
    "english_text = read_file(transcript_filepath)\n",
    "\n",
    "\n",
    "my_exclude_terms = [\"Abilities\", \"character\", \"icon\", \"players\", \"player\", \"play\", \"damage\", \"normal attack\", \"action\", \"actions\"]\n",
    "\n",
    "exclude_terms = detect_terms_to_exclude(english_text)\n",
    "exclude_terms = exclude_terms + my_exclude_terms\n",
    "\n",
    "exclude_terms = list(set(exclude_terms))\n",
    "print(\"Terms to Exclude:\", exclude_terms)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_terms = {\n",
    "        \"for each character\": \"character တစ်ကောင်ချင်းစီအတွက်\",\n",
    "    }\n",
    "\n",
    "transcript_filepath = \"transcripts/transcript.txt\"\n",
    "\n",
    "original_timestamp_text = read_file(transcript_filepath)\n",
    "\n",
    "system_prompt = generate_system_prompt(exclude_terms=exclude_terms, custom_terms=custom_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "import openai\n",
    "# Check if the server is running\n",
    "response = requests.get(\"http://localhost:11434\")\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Ollama Server is not running!\")\n",
    "\n",
    "\n",
    "\n",
    "# Connect to your local Ollama instance\n",
    "client = openai.Client(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"  \n",
    ")\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"deepseek-r1\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n",
    "#     temperature=0.5\n",
    "# )\n",
    "\n",
    "user_message = f\"Here is the English text that needs to be translated to Burmese (Myanmar): {english_text}\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Translate the following English text to Burmese (Myanmar) while keeping the original English terms for special terms.\n",
      "    Please exclude the following terms from translation: \n",
      "    - Energy\n",
      "- damage\n",
      "- players\n",
      "- Abilities\n",
      "- an Outro Skill\n",
      "- actions\n",
      "- Concerto Energy\n",
      "- Ult\n",
      "- Concerto Energy / Outro /\n",
      "- Forte Circuit\n",
      "- icon\n",
      "- Concerto\n",
      "- action\n",
      "- Circuit\n",
      "- play\n",
      "- normal attack\n",
      "- Skill\n",
      "- player\n",
      "- Gadget\n",
      "- Forte\n",
      "- Intro\n",
      "- Outro\n",
      "- Echo\n",
      "- character\n",
      "    Also, translate the following custom terms as specified:\n",
      "    'for each character' => 'character တစ်ကောင်ချင်းစီအတွက်'\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\[\\d+\\.\\d{2} - \\d+\\.\\d{2}\\]\"\n",
    " \n",
    " \n",
    "text = read_file(\"transcripts/transcript.txt\") \n",
    "timestamps = re.findall(pattern, text)\n",
    "\n",
    "time_stamps =\"\" \n",
    "time_stamps += \"\\n\".join(timestamps)\n",
    "\n",
    "save_file(\"timestamps.txt\", time_stamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript (Myanmar): ကဲ ဒါဆိုရင်တော့,\n",
      "segment (English): character\n",
      "transcript (Myanmar): ရဲ့\n",
      "segment (English): Abilities\n",
      "transcript (Myanmar): တွေကို စတင်ကြည့်ရှုရအောင်\n",
      "segment (English): Ult\n",
      "segment (English): Echo\n",
      "segment (English): Skill\n",
      "segment (English): Gadget\n",
      "segment (English): Forte\n",
      "segment (English): Circuit\n",
      "transcript (Myanmar): , နဲ့\n",
      "segment (English): Concerto\n",
      "segment (English): Energy\n",
      "transcript (Myanmar): .\n",
      "ဒါတွေက\n",
      "segment (English): character\n",
      "transcript (Myanmar): တစ်ကောင်ချင်းစီအတွက်\n",
      "အဓိက\n",
      "segment (English): Abilities\n",
      "transcript (Myanmar): တွေဖြစ်ပါတယ်။\n",
      "ပုံကဝိုင်း\n",
      "segment (English): icon\n",
      "transcript (Myanmar): လေးဟာ\n",
      "segment (English): lock\n",
      "segment (English): on\n",
      "segment (English): feature\n",
      "transcript (Myanmar): ဖြစ်ပါတယ်။\n",
      "Audio saved as samples/combined_audio_3538434f-5cf9-4cdf-ae9f-bdecb647cf74.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import uuid\n",
    "from transformers import pipeline\n",
    "import soundfile as sf\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "myanmar_model_name = \"facebook/mms-tts-mya\"\n",
    "english_model_name = \"facebook/mms-tts-eng\"\n",
    "myanmar_model = pipeline(\"text-to-speech\", model=myanmar_model_name)\n",
    "english_model = pipeline(\"text-to-speech\", model=english_model_name)\n",
    "\n",
    "sample_rate = 16000\n",
    "pause_duration = 0.5  \n",
    "\n",
    "myanmar_text = \"\"\"\n",
    "ကဲ ဒါဆိုရင်တော့, character ရဲ့ Abilities တွေကို စတင်ကြည့်ရှုရအောင်\n",
    "Ult, Echo, Skill, Gadget, Forte Circuit, နဲ့ Concerto Energy.\n",
    "ဒါတွေက character တစ်ကောင်ချင်းစီအတွက်\n",
    "အဓိက Abilities တွေဖြစ်ပါတယ်။\n",
    "ပုံကဝိုင်း icon လေးဟာ  lock-on feature ဖြစ်ပါတယ်။\n",
    "\"\"\"\n",
    "\n",
    "def generate_audio(text, model):\n",
    "    speech = model(text)\n",
    "    audio_data = speech[\"audio\"]\n",
    "    if audio_data.ndim == 2 and audio_data.shape[0] == 1:\n",
    "        audio_data = audio_data.squeeze(0)\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "# Extract English words and Myanmar text segments\n",
    "segments = re.split(r'(\\b[A-Za-z]+\\b)', myanmar_text)\n",
    "audio_segments = []\n",
    "\n",
    "for segment in segments:\n",
    "    segment = segment.strip()\n",
    "    if not segment:\n",
    "        continue\n",
    "    if re.match(r'^[A-Za-z]+$', segment):\n",
    "     \n",
    "        print(f\"segment (English): {segment}\")\n",
    "        audio_segments.append(generate_audio(segment, english_model))\n",
    "    else:\n",
    "        if segment.strip() in [\",\", \".\", \"။\", \"၊\", \":\", \";\",\"-\"]:\n",
    "            continue\n",
    "      \n",
    "        print(f\"transcript (Myanmar): {segment}\")\n",
    "        audio_segments.append(generate_audio(segment, myanmar_model))\n",
    "    \n",
    "    # Add pause for newline characters\n",
    "    if '\\n' in segment:\n",
    "        pause = np.zeros(int(pause_duration * sample_rate)) \n",
    "        audio_segments.append(pause)\n",
    "\n",
    "# Combine all audio segments\n",
    "combined_audio = np.concatenate(audio_segments)\n",
    " \n",
    "random_uuid = uuid.uuid4()\n",
    "output_file = f\"samples/combined_audio_{random_uuid}.wav\"\n",
    "sf.write(output_file, combined_audio, sample_rate)\n",
    "print(f\"Audio saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch: Local file found, copying 'C:\\Users\\heinm\\.cache\\huggingface\\hub\\models--speechbrain--tts-tacotron2-ljspeech\\snapshots\\d01e530d6d8e1b388c04b882305867addbed4389\\hyperparams.yaml' -> 'c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\tmpdir_tts\\hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n",
      "c:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n",
      "INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/tts-tacotron2-ljspeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b78b402a4f473ebdfaaaacabbd8c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.ckpt:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\heinm\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--tts-tacotron2-ljspeech\\\\snapshots\\\\d01e530d6d8e1b388c04b882305867addbed4389\\\\model.ckpt' -> 'c:\\\\Users\\\\heinm\\\\OneDrive\\\\Desktop\\\\mm-tts\\\\tmpdir_tts\\\\model.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfetching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalStrategy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize TTS (tacotron2) and Vocoder (HiFIGAN) with copy strategy\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m tacotron2 \u001b[38;5;241m=\u001b[39m \u001b[43mTacotron2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hparams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeechbrain/tts-tacotron2-ljspeech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmpdir_tts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLocalStrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOPY\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m hifi_gan \u001b[38;5;241m=\u001b[39m HIFIGAN\u001b[38;5;241m.\u001b[39mfrom_hparams(\n\u001b[0;32m     12\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain/tts-hifigan-ljspeech\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     13\u001b[0m     savedir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmpdir_vocoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     14\u001b[0m     local_strategy\u001b[38;5;241m=\u001b[39mLocalStrategy\u001b[38;5;241m.\u001b[39mCOPY\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Running the TTS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py:520\u001b[0m, in \u001b[0;36mPretrained.from_hparams\u001b[1;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, huggingface_cache_dir, overrides_must_match, local_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m pretrainer\u001b[38;5;241m.\u001b[39mset_collect_in(savedir)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# For distributed setups, have this here:\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m \u001b[43mrun_on_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_source\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_auth_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Load on the CPU. Later the params can be moved elsewhere by specifying\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m download_only:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# run_opts={\"device\": ...}\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:105\u001b[0m, in \u001b[0;36mrun_on_main\u001b[1;34m(func, args, kwargs, post_func, post_args, post_kwargs, run_post_on_main)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     post_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 105\u001b[0m \u001b[43mmain_process_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m ddp_barrier()\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:168\u001b[0m, in \u001b[0;36mmain_process_only.<locals>.main_proc_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m MainProcessContext():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m if_main_process():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:289\u001b[0m, in \u001b[0;36mPretrainer.collect_files\u001b[1;34m(self, default_source, use_auth_token, local_strategy)\u001b[0m\n\u001b[0;32m    280\u001b[0m     path \u001b[38;5;241m=\u001b[39m fetch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# run fetch() on the main process, potentially performing downloading\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# which we do NOT want to happen concurrently.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# path needs to be available only if it is a local source w/o symlink\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43mrun_on_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_fetch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_fetch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m loadable_paths[name] \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, FetchSource):\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:105\u001b[0m, in \u001b[0;36mrun_on_main\u001b[1;34m(func, args, kwargs, post_func, post_args, post_kwargs, run_post_on_main)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     post_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 105\u001b[0m \u001b[43mmain_process_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m ddp_barrier()\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:168\u001b[0m, in \u001b[0;36mmain_process_only.<locals>.main_proc_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m MainProcessContext():\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m if_main_process():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:280\u001b[0m, in \u001b[0;36mPretrainer.collect_files.<locals>.run_fetch\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Very basic local wrapper to fetch to store the path in a\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mlocal of collect_files\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m**kwargs : dict\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m    Arguments to forward to fetch\"\"\"\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m path\n\u001b[1;32m--> 280\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:398\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, allow_updates, allow_network, save_filename, use_auth_token, revision, huggingface_cache_dir, local_strategy)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found on HF hub\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlink_with_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetched_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heinm\\OneDrive\\Desktop\\mm-tts\\.venv\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:162\u001b[0m, in \u001b[0;36mlink_with_strategy\u001b[1;34m(src, dst, local_strategy)\u001b[0m\n\u001b[0;32m    157\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetch: Local file found, creating symlink \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, src, dst\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     dst\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# remove link or delete file\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_strategy \u001b[38;5;129;01min\u001b[39;00m (LocalStrategy\u001b[38;5;241m.\u001b[39mCOPY, LocalStrategy\u001b[38;5;241m.\u001b[39mCOPY_SKIP_CACHE):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.8-windows-x86_64-none\\Lib\\pathlib.py:1386\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymlink\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.symlink() not available on this system\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1386\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\heinm\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--tts-tacotron2-ljspeech\\\\snapshots\\\\d01e530d6d8e1b388c04b882305867addbed4389\\\\model.ckpt' -> 'c:\\\\Users\\\\heinm\\\\OneDrive\\\\Desktop\\\\mm-tts\\\\tmpdir_tts\\\\model.ckpt'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
