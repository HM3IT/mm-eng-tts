{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hm3/Desktop/mm-tts/.venv/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import whisper\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    " \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    " \n",
    "model = whisper.load_model(\"base\", device=device)\n",
    "\n",
    "def download_audio(youtube_url, output_path=\"audio.mp3\"):\n",
    "    \"\"\"Download the audio from a YouTube video.\"\"\"\n",
    "    try:\n",
    "        command = [\n",
    "            \"yt-dlp\",\n",
    "            \"--format\", \"bestaudio\",\n",
    "            \"--extract-audio\",\n",
    "            \"--audio-format\", \"mp3\",\n",
    "            \"--output\", output_path,\n",
    "            youtube_url,\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Audio downloaded to {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribe the audio using Whisper.\"\"\"\n",
    "    try:\n",
    "        print(\"Extracting transcript\")\n",
    "        result = model.transcribe(audio_path)\n",
    "        return result  # Contains text and timestamps\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_transcript_with_timestamps(transcript, output_file=\"transcript.txt\"):\n",
    "    \"\"\"Save the transcript with timestamps to a file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file, \"w\") as file:\n",
    "            for segment in transcript['segments']:\n",
    "                start_time = segment['start']\n",
    "                end_time = segment['end']\n",
    "                text = segment['text']\n",
    "                file.write(f\"[{start_time:.2f} - {end_time:.2f}] {text}\\n\")\n",
    "        print(f\"Transcript saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transcript: {e}\")\n",
    "\n",
    "def detect_terms_to_exclude(text:str):\n",
    "    \"\"\"Detect terms that are likely to be technical or domain-specific.\"\"\"\n",
    "  \n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "    patterns = [\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"machine\"},\n",
    "                {\"lower\": \"learning\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"artificial\"},\n",
    "                {\"lower\": \"intelligence\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"lower\": \"data\"},\n",
    "                {\"lower\": \"science\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"ML\"},\n",
    "            ]\n",
    "        },\n",
    "          {\n",
    "            \"label\": \"PERSON\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"Rover\"},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"TECH\",\n",
    "            \"pattern\": [{\"TEXT\": {\"REGEX\": \"(?i)^ai$\"}}]\n",
    "        },\n",
    "        {\n",
    "                \"label\": \"LINK\",\n",
    "                \"pattern\": [\n",
    "                    {\"TEXT\": {\"REGEX\": r\"https?://[^\\s]+\"}}\n",
    "                ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\") \n",
    "    ruler.add_patterns(patterns)\n",
    "\n",
    "    doc = nlp(text)     \n",
    " \n",
    "    exclude_terms = []\n",
    " \n",
    "    for ent in doc.ents:\n",
    "        exclude_terms.append(ent.text)\n",
    "    \n",
    " \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\" or (token.is_upper and len(token) > 1):  \n",
    "            exclude_terms.append(token.text)\n",
    "\n",
    "    exclude_terms = [term for term in exclude_terms if not re.search(r\"(\\n|%|\\d{1,2}%|^\\d{1,2}$)\", term)]\n",
    "    exclude_terms = list(set(exclude_terms))\n",
    "    \n",
    "    return exclude_terms\n",
    "\n",
    " \n",
    " \n",
    "def generate_system_prompt(exclude_terms:list|None=None, custom_terms:dict|None=None):\n",
    " \n",
    "    if exclude_terms is None:\n",
    "        exclude_terms = []\n",
    "    if custom_terms is None:\n",
    "        custom_terms = {}\n",
    " \n",
    "    exclusion_text = \", \".join([f\"{term}\" for term in exclude_terms])\n",
    "    exclusion_text.rstrip(\",\")\n",
    "    exclusion_text += \".\"\n",
    "    custom_terms_text = \"\\n\".join([f\"'{eng_term}' => '{myanmar_term}'\" for eng_term, myanmar_term in custom_terms.items()])\n",
    "\n",
    " \n",
    "    prompt = f\"\"\"\n",
    "    Translate the following English text to Burmese (Myanmar) while keeping the original English terms for special terms.\n",
    "    Please exclude the following terms from translation: \n",
    "    {exclusion_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    if custom_terms:\n",
    "        prompt += f\"\"\"Also, translate the following custom terms as specified:\n",
    "    {custom_terms_text}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def save_file(filepath: str, content: str):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "        \n",
    "def read_file(filepath:str):\n",
    "    with open(filepath , \"r\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=DmgGGUYn2c8\"\n",
    "output_filename = \"trnascript.txt\"\n",
    "audio_file = download_audio(youtube_url)\n",
    "\n",
    "if audio_file:\n",
    "\n",
    "    transcript = transcribe_audio(audio_file)\n",
    "    \n",
    "    if transcript:\n",
    "\n",
    "        save_transcript_with_timestamps(transcript, output_filename)\n",
    "\n",
    "    os.remove(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hm3/Desktop/mm-tts/.venv/lib/python3.12/site-packages/thinc/shims/pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms to Exclude: ['Concerto Energy / Outro /', 'an Outro Skill', 'play', 'action', 'Skill', 'Ult', 'Echo', 'character', 'players', 'damage', 'Concerto Energy', 'Forte Circuit', 'Forte', 'Concerto', 'player', 'actions', 'Intro', 'Energy', 'Outro', 'normal attack', 'icon', 'Abilities', 'Gadget', 'Circuit']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "transcript_filepath = \"transcripts/transcript.txt\"\n",
    "\n",
    "english_text = read_file(transcript_filepath)\n",
    "\n",
    "\n",
    "my_exclude_terms = [\"Abilities\", \"character\", \"icon\", \"players\", \"player\", \"play\", \"damage\", \"normal attack\", \"action\", \"actions\"]\n",
    "\n",
    "exclude_terms = detect_terms_to_exclude(english_text)\n",
    "exclude_terms = exclude_terms + my_exclude_terms\n",
    "\n",
    "exclude_terms = list(set(exclude_terms))\n",
    "print(\"Terms to Exclude:\", exclude_terms)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_terms = {\n",
    "        \"for each character\": \"character တစ်ကောင်ချင်းစီအတွက်\",\n",
    "    }\n",
    "\n",
    "transcript_filepath = \"transcripts/transcript.txt\"\n",
    "\n",
    "original_timestamp_text = read_file(transcript_filepath)\n",
    "\n",
    "\n",
    "system_prompt = generate_system_prompt(exclude_terms=exclude_terms, custom_terms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Translate the following English text to Burmese (Myanmar) while keeping the original English terms for special terms.\n",
      "    Please exclude the following terms from translation: \n",
      "    Concerto Energy / Outro /, an Outro Skill, play, action, Skill, Ult, Echo, character, players, damage, Concerto Energy, Forte Circuit, Forte, Concerto, player, actions, Intro, Energy, Outro, normal attack, icon, Abilities, Gadget, Circuit.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama status: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "import openai\n",
    "\n",
    "response = requests.get(\"http://localhost:11434\")\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Ollama Server is not running!\")\n",
    "\n",
    "print(f\"Ollama status: {response.status_code}\")\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"  \n",
    ")\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Translate this:\n",
    "{english_text}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ],\n",
    "    stream=False,\n",
    "    \n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translated Result:\n",
      "Here’s an attempt to translate your text into Burmese (Myanmar) while keeping a few of the terms you listed in English:\n",
      "\n",
      "---\n",
      "\n",
      "I think it's time to teach new players how to play the game, solet's get into it!\n",
      "Aberations\n",
      "\n",
      "Let's start with the character's aberations: the Ult, Echo, skill, gadget, Forte Circuit, and Concerto Energy. These are the primary aberations for each character. If you're wondering about the small circular icon, that's the lock-on feature.\n",
      "Concerto Energy / Outro / Intro\n",
      "\n",
      "Concerto Energy is a resource that needs to be filled to use certain abilities. You gain this energy by performing attacks or other actions in battle. Once the gauge is full, you can cast an ability called an Outro Skill by switching to another character.\n",
      "\n",
      "---\n",
      "\n",
      "I hope this helps!\n"
     ]
    }
   ],
   "source": [
    "# Extract the <think> section\n",
    "think_match = re.search(r'<think>(.*?)</think>', response, re.DOTALL)\n",
    "think_section = think_match.group(1).strip() if think_match else None\n",
    "\n",
    "# Extract the translated result\n",
    "translated_result = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
    "\n",
    "# print(\"Think Section:\")\n",
    "# print(think_section)\n",
    "print(\"\\nTranslated Result:\")\n",
    "print(translated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Deepseek:\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hello! I'm just a virtual assistant, so I don't have feelings, but thanks for asking! How are *you* doing today? 😊\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Ollama server URL\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Define the payload for the API request\n",
    "payload = {\n",
    "    \"model\": \"deepseek-r1:7b\",  # Replace with your model name\n",
    "    \"prompt\": \"Hello, how are you?\",  # Your input prompt\n",
    "    \"stream\": False  # Set to True if you want streaming responses\n",
    "}\n",
    "\n",
    "# Send a POST request to the Ollama API\n",
    "response = requests.post(OLLAMA_URL, json=payload)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Print the response from the model\n",
    "    print(\"Response from Deepseek:\")\n",
    "    print(response.json().get(\"response\"))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\[\\d+\\.\\d{2} - \\d+\\.\\d{2}\\]\"\n",
    " \n",
    " \n",
    "text = read_file(\"transcripts/transcript.txt\") \n",
    "timestamps = re.findall(pattern, text)\n",
    "\n",
    "time_stamps =\"\" \n",
    "time_stamps += \"\\n\".join(timestamps)\n",
    "\n",
    "save_file(\"timestamps.txt\", time_stamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript (Myanmar): ကဲ ဒါဆိုရင်တော့,\n",
      "segment (English): character\n",
      "transcript (Myanmar): ရဲ့\n",
      "segment (English): Abilities\n",
      "transcript (Myanmar): တွေကို စတင်ကြည့်ရှုရအောင်\n",
      "segment (English): Ult\n",
      "segment (English): Echo\n",
      "segment (English): Skill\n",
      "segment (English): Gadget\n",
      "segment (English): Forte\n",
      "segment (English): Circuit\n",
      "transcript (Myanmar): , နဲ့\n",
      "segment (English): Concerto\n",
      "segment (English): Energy\n",
      "transcript (Myanmar): .\n",
      "ဒါတွေက\n",
      "segment (English): character\n",
      "transcript (Myanmar): တစ်ကောင်ချင်းစီအတွက်\n",
      "အဓိက\n",
      "segment (English): Abilities\n",
      "transcript (Myanmar): တွေဖြစ်ပါတယ်။\n",
      "ပုံကဝိုင်း\n",
      "segment (English): icon\n",
      "transcript (Myanmar): လေးဟာ\n",
      "segment (English): lock\n",
      "segment (English): on\n",
      "segment (English): feature\n",
      "transcript (Myanmar): ဖြစ်ပါတယ်။\n",
      "Audio saved as samples/combined_audio_3538434f-5cf9-4cdf-ae9f-bdecb647cf74.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import uuid\n",
    "from transformers import pipeline\n",
    "import soundfile as sf\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "myanmar_model_name = \"facebook/mms-tts-mya\"\n",
    "english_model_name = \"facebook/mms-tts-eng\"\n",
    "myanmar_model = pipeline(\"text-to-speech\", model=myanmar_model_name)\n",
    "english_model = pipeline(\"text-to-speech\", model=english_model_name)\n",
    "\n",
    "sample_rate = 16000\n",
    "pause_duration = 0.5  \n",
    "\n",
    "myanmar_text = \"\"\"\n",
    "ကဲ ဒါဆိုရင်တော့, character ရဲ့ Abilities တွေကို စတင်ကြည့်ရှုရအောင်\n",
    "Ult, Echo, Skill, Gadget, Forte Circuit, နဲ့ Concerto Energy.\n",
    "ဒါတွေက character တစ်ကောင်ချင်းစီအတွက်\n",
    "အဓိက Abilities တွေဖြစ်ပါတယ်။\n",
    "ပုံကဝိုင်း icon လေးဟာ  lock-on feature ဖြစ်ပါတယ်။\n",
    "\"\"\"\n",
    "\n",
    "def generate_audio(text, model):\n",
    "    speech = model(text)\n",
    "    audio_data = speech[\"audio\"]\n",
    "    if audio_data.ndim == 2 and audio_data.shape[0] == 1:\n",
    "        audio_data = audio_data.squeeze(0)\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "# Extract English words and Myanmar text segments\n",
    "segments = re.split(r'(\\b[A-Za-z]+\\b)', myanmar_text)\n",
    "audio_segments = []\n",
    "\n",
    "for segment in segments:\n",
    "    segment = segment.strip()\n",
    "    if not segment:\n",
    "        continue\n",
    "    if re.match(r'^[A-Za-z]+$', segment):\n",
    "     \n",
    "        print(f\"segment (English): {segment}\")\n",
    "        audio_segments.append(generate_audio(segment, english_model))\n",
    "    else:\n",
    "        if segment.strip() in [\",\", \".\", \"။\", \"၊\", \":\", \";\",\"-\"]:\n",
    "            continue\n",
    "      \n",
    "        print(f\"transcript (Myanmar): {segment}\")\n",
    "        audio_segments.append(generate_audio(segment, myanmar_model))\n",
    "    \n",
    "    # Add pause for newline characters\n",
    "    if '\\n' in segment:\n",
    "        pause = np.zeros(int(pause_duration * sample_rate)) \n",
    "        audio_segments.append(pause)\n",
    "\n",
    "# Combine all audio segments\n",
    "combined_audio = np.concatenate(audio_segments)\n",
    " \n",
    "random_uuid = uuid.uuid4()\n",
    "output_file = f\"samples/combined_audio_{random_uuid}.wav\"\n",
    "sf.write(output_file, combined_audio, sample_rate)\n",
    "print(f\"Audio saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: ['ကျွန်တော် က ၎င်း သည် ကစား ပွဲ ကို ဘယ်လို ကစား ရ မ လဲ ဆိုတာ ကစား သမား အသစ် များ ကို သင်ကြား ရန် အချိန် ဖြစ် တယ် လို့ ထင် ပါ တယ် ၊ ဒါကြောင့် ကျွန်တော် တို့ ၎င်း ထဲ သို့ သွား ပါ စို့ ! စွမ်းရည် များ ကစား သမား များ ၏ စွမ်းရည် များ နှင့်အတူ စတင် ပါ စို့ : အယ်လ်တ် ၊ အီချို ၊ စွမ်းရည် ၊ ဂတ်ဂျက် ၊ ဖဲတာ ဆားကစ် ၊ နှင့် ကွန်ရက်တို စွမ်းအင် ။ ထို အရာ များ သည် ဇာတ်ကောင် တစ် ယောက် စီ အတွက် မူလ စွမ်းရည် များ ဖြစ် ကြ သည် ။ အကယ်၍ သင် သည် သေးငယ် သော ပတ်ပတ်လည် အိုင်ကွန် နှင့် ပတ်သက် ၍ စဉ်းစား နေ လျှင် ၊ ထို အရာ သည် လော့-オン ပုံစံ ဖြစ် ']\n"
     ]
    }
   ],
   "source": [
    "# Eng to Myanmar Translation using MBart\n",
    "\n",
    "\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    " \n",
    "myanmar_text = text\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# Translate Eng to Myanmar\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "encoded_hi = tokenizer(myanmar_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(\n",
    "    **encoded_hi,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"my_MM\"]\n",
    ")\n",
    "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(\"Translation:\", translation)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
